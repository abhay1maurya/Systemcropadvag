{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79994a0a-7b59-4d22-a933-21198d3c5b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5d3d1-0eaa-433a-bf10-0af87dfe778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "# ==============================================================================\n",
    "file_path = 'crop_recommendation_dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"‚úÖ Data Loaded. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå CRITICAL ERROR: '{file_path}' not found. Run the data repair script first.\")\n",
    "    raise\n",
    "\n",
    "# 2. Safety Check (Drop classes with < 2 samples)\n",
    "# ==============================================================================\n",
    "class_counts = df['label'].value_counts()\n",
    "rogue_classes = class_counts[class_counts < 2].index\n",
    "\n",
    "if len(rogue_classes) > 0:\n",
    "    print(f\"‚ö†Ô∏è Dropping {len(rogue_classes)} classes with < 2 samples.\")\n",
    "    df = df[~df['label'].isin(rogue_classes)].copy()\n",
    "else:\n",
    "    print(\"‚úÖ Data Check Passed: All classes are valid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4ce5bfc-5520-486d-b1c1-3aff5fafbe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Engineering Biological Features...\n",
      "‚úÖ Feature Order Saved: ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'N_ratio', 'P_ratio', 'K_ratio', 'aridity_index', 'water_stress']\n",
      "‚úÖ Data Scaled & Split.\n",
      "   Training Data: (24424, 12)\n"
     ]
    }
   ],
   "source": [
    "# 3. Feature Engineering (The Accuracy Booster)\n",
    "# ==============================================================================\n",
    "print(\"üß† Engineering Biological Features...\")\n",
    "\n",
    "def add_smart_features(data):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # A. Nutrient Ratios\n",
    "    df['total_nutrients'] = df['N'] + df['P'] + df['K'] + 1e-5\n",
    "    df['N_ratio'] = df['N'] / df['total_nutrients']\n",
    "    df['P_ratio'] = df['P'] / df['total_nutrients']\n",
    "    df['K_ratio'] = df['K'] / df['total_nutrients']\n",
    "    \n",
    "    # B. Climate Interactions\n",
    "    df['aridity_index'] = df['rainfall'] / (df['temperature'] + 1e-5)\n",
    "    df['water_stress'] = df['temperature'] * (100 - df['humidity'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_engineered = add_smart_features(df)\n",
    "\n",
    "# 4. Prepare X and y\n",
    "# ==============================================================================\n",
    "# We DROP 'total_nutrients' to avoid redundancy (multicollinearity)\n",
    "X = df_engineered.drop(['label', 'total_nutrients'], axis=1)\n",
    "y = df_engineered['label']\n",
    "\n",
    "# SAVE FEATURE ORDER (Critical for Deployment)\n",
    "feature_order = X.columns.tolist()\n",
    "joblib.dump(feature_order, 'feature_order.pkl')\n",
    "print(f\"‚úÖ Feature Order Saved: {feature_order}\")\n",
    "\n",
    "# 5. Encoding & Splitting\n",
    "# ==============================================================================\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# 6. Scaling\n",
    "# ==============================================================================\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Data Scaled & Split.\")\n",
    "print(f\"   Training Data: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96784a4b-ea07-4b8a-8f27-2c6585c1c2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuring Architectures...\n",
      "‚úÖ Configuration Ready.\n"
     ]
    }
   ],
   "source": [
    "# 7. Define Hyperparameter Search Spaces\n",
    "# ==============================================================================\n",
    "print(\"‚öôÔ∏è Configuring Architectures...\")\n",
    "\n",
    "# Random Forest\n",
    "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_params = {\n",
    "    'n_estimators': randint(200, 500),\n",
    "    'max_depth': [20, 25, 30, None],\n",
    "    'min_samples_leaf': randint(1, 4),\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# KNN\n",
    "knn_base = KNeighborsClassifier(n_jobs=-1)\n",
    "knn_params = {\n",
    "    'n_neighbors': randint(5, 15),\n",
    "    'weights': ['distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# XGBoost\n",
    "xgb_base = xgb.XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "xgb_params = {\n",
    "    'n_estimators': randint(200, 400),\n",
    "    'learning_rate': uniform(0.01, 0.15),\n",
    "    'max_depth': randint(5, 10),\n",
    "    'subsample': uniform(0.7, 0.3)\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83d7d048-5926-4ca6-a114-34703532545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Training Pipeline (This takes time)...\n",
      "\n",
      "üîé Tuning Random Forest...\n",
      "\n",
      "üîé Tuning KNN...\n",
      "\n",
      "üîé Tuning XGBoost...\n",
      "\n",
      "   RF Best: 0.9041\n",
      "   KNN Best: 0.8760\n",
      "   XGB Best: 0.8997\n",
      "\n",
      "üèóÔ∏è Training Stacking Meta-Model...\n",
      "\n",
      "‚úÖ Final Stacking Model Trained.\n"
     ]
    }
   ],
   "source": [
    "# 8. Training Pipeline\n",
    "# ==============================================================================\n",
    "def train_stacking_model(X_train, y_train):\n",
    "    print(\"üöÄ Starting Training Pipeline (This takes time)...\")\n",
    "    \n",
    "    # Phase 1: Optimize Base Models\n",
    "    print(\"\\nüîé Tuning Random Forest...\")\n",
    "    rf_opt = RandomizedSearchCV(rf_base, rf_params, n_iter=10, cv=3, n_jobs=-1, random_state=42)\n",
    "    rf_opt.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nüîé Tuning KNN...\")\n",
    "    knn_opt = RandomizedSearchCV(knn_base, knn_params, n_iter=5, cv=3, n_jobs=-1, random_state=42)\n",
    "    knn_opt.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nüîé Tuning XGBoost...\")\n",
    "    xgb_opt = RandomizedSearchCV(xgb_base, xgb_params, n_iter=10, cv=3, n_jobs=-1, random_state=42)\n",
    "    xgb_opt.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"\\n   RF Best: {rf_opt.best_score_:.4f}\")\n",
    "    print(f\"   KNN Best: {knn_opt.best_score_:.4f}\")\n",
    "    print(f\"   XGB Best: {xgb_opt.best_score_:.4f}\")\n",
    "    \n",
    "    # Phase 2: Stacking (The \"Boss\" Model)\n",
    "    print(\"\\nüèóÔ∏è Training Stacking Meta-Model...\")\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_opt.best_estimator_),\n",
    "            ('knn', knn_opt.best_estimator_),\n",
    "            ('xgb', xgb_opt.best_estimator_)\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=3,\n",
    "        n_jobs=1  # <--- CRITICAL FIX FOR WINDOWS CRASH\n",
    "    )\n",
    "    \n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    return stacking_clf\n",
    "\n",
    "# Execute\n",
    "final_model = train_stacking_model(X_train_scaled, y_train)\n",
    "print(\"\\n‚úÖ Final Stacking Model Trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48e82ca-54e4-43bc-a2b5-135920c2648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating on Test Set...\n",
      "\n",
      "üèÜ Final Test Accuracy: 93.71%\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      almond       0.83      0.88      0.85        40\n",
      "       apple       0.96      0.62      0.76        40\n",
      "     apricot       0.91      0.97      0.94        40\n",
      "   asparagus       0.97      0.95      0.96        40\n",
      "      banana       0.99      1.00      1.00       147\n",
      "      barley       0.95      0.89      0.92       101\n",
      "    beetroot       0.88      0.90      0.89        40\n",
      " bell_pepper       0.86      0.93      0.89        40\n",
      " bittergourd       1.00      1.00      1.00        40\n",
      "  black_gram       0.99      0.99      0.99       102\n",
      "  blackberry       0.93      0.93      0.93        40\n",
      "   blueberry       1.00      0.97      0.99        40\n",
      " bottlegourd       1.00      1.00      1.00        40\n",
      "    broccoli       0.80      0.97      0.88        40\n",
      "     cabbage       0.89      0.80      0.84        40\n",
      "      carrot       0.88      0.93      0.90        40\n",
      "      castor       0.86      0.90      0.88        40\n",
      " cauliflower       0.74      0.88      0.80        40\n",
      "      celery       0.85      0.88      0.86        40\n",
      "      cherry       0.88      0.95      0.92        40\n",
      "    chickpea       0.94      0.93      0.93       100\n",
      "       chili       0.93      0.97      0.95        40\n",
      "        corn       0.98      0.98      0.98       239\n",
      "      cotton       0.96      0.96      0.96       165\n",
      "    cucumber       0.97      0.82      0.89        40\n",
      "    eggplant       0.95      0.90      0.92        40\n",
      " french_bean       0.93      0.97      0.95        40\n",
      "      grapes       0.95      0.92      0.94       104\n",
      "       guava       0.92      0.90      0.91        40\n",
      "  horse_gram       1.00      1.00      1.00       109\n",
      "        jute       0.98      1.00      0.99       120\n",
      "kidney_beans       0.93      0.94      0.94       100\n",
      "      lentil       1.00      0.98      0.99       100\n",
      "     lettuce       0.89      0.78      0.83        40\n",
      "     linseed       0.89      0.78      0.83        40\n",
      "      lychee       0.95      0.95      0.95        40\n",
      "       mango       0.98      0.99      0.99       111\n",
      "       moong       0.98      1.00      0.99       206\n",
      "  moth_beans       0.82      0.84      0.83        99\n",
      "   muskmelon       0.89      0.84      0.87       100\n",
      "     mustard       0.74      0.93      0.82        40\n",
      "         oat       0.97      0.95      0.96        40\n",
      "        okra       0.89      0.85      0.87        40\n",
      "       onion       0.98      0.95      0.96       173\n",
      "      orange       0.99      0.98      0.99       104\n",
      "      papaya       0.99      0.97      0.98       110\n",
      "       peach       0.70      0.82      0.76        40\n",
      "      peanut       0.84      0.80      0.82       119\n",
      "        pear       0.87      0.97      0.92        40\n",
      "pearl_millet       0.93      0.97      0.95        40\n",
      "        peas       1.00      1.00      1.00        40\n",
      " pigeon_peas       0.92      0.94      0.93       100\n",
      "        plum       0.77      0.75      0.76        40\n",
      " pomegranate       0.92      0.93      0.93       100\n",
      "      potato       0.99      0.95      0.97       210\n",
      "     pumpkin       0.91      0.78      0.84        40\n",
      "      radish       0.95      0.95      0.95        40\n",
      "        ragi       1.00      1.00      1.00       117\n",
      "    rapeseed       0.97      0.97      0.97       164\n",
      "   raspberry       0.95      0.97      0.96        40\n",
      "        rice       0.99      0.97      0.98       264\n",
      "   safflower       0.79      0.82      0.80        40\n",
      "      sesame       0.92      0.85      0.88        40\n",
      "     sorghum       0.95      0.96      0.96       167\n",
      "    soyabean       0.92      0.94      0.93       104\n",
      "     spinach       0.80      0.82      0.81        40\n",
      "      squash       0.79      0.95      0.86        40\n",
      "  strawberry       0.88      0.90      0.89        40\n",
      "   sugarcane       0.95      0.97      0.96        40\n",
      "   sunflower       0.96      0.98      0.97       165\n",
      "sweet_potato       0.99      0.98      0.99       116\n",
      "        taro       0.98      1.00      0.99        40\n",
      "     tobacco       0.85      0.85      0.85        40\n",
      "      tomato       0.95      0.97      0.96        40\n",
      "      turnip       0.88      0.93      0.90        40\n",
      "      walnut       0.81      0.85      0.83        40\n",
      "  watermelon       0.88      0.87      0.87       100\n",
      "       wheat       0.99      0.92      0.96       130\n",
      "         yam       0.95      0.97      0.96        40\n",
      "    zucchini       0.80      0.88      0.83        40\n",
      "\n",
      "    accuracy                           0.94      6106\n",
      "   macro avg       0.92      0.92      0.92      6106\n",
      "weighted avg       0.94      0.94      0.94      6106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Evaluation\n",
    "# ==============================================================================\n",
    "print(\"üìä Evaluating on Test Set...\")\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nüèÜ Final Test Accuracy: {acc*100:.2f}%\")\n",
    "print(\"-\" * 30)\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "727ea189-907e-4191-804e-0a213abd876e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Success! All 4 files saved (Model, Scaler, Encoder, FeatureOrder).\n"
     ]
    }
   ],
   "source": [
    "# 10. Save Artifacts\n",
    "# ==============================================================================\n",
    "joblib.dump(final_model, 'crop_model_final.pkl')\n",
    "joblib.dump(scaler, 'scaler_final.pkl')\n",
    "joblib.dump(le, 'label_encoder_final.pkl')\n",
    "# feature_order.pkl was saved in Cell 2\n",
    "\n",
    "print(\"üíæ Success! All 4 files saved (Model, Scaler, Encoder, FeatureOrder).\")\n",
    "\n",
    "# 11. Test Prediction Function (Deployment Ready)\n",
    "# ==============================================================================\n",
    "def test_prediction(N, P, K, temp, hum, ph, rain):\n",
    "    # Load\n",
    "    model = joblib.load('crop_model_final.pkl')\n",
    "    sc = joblib.load('scaler_final.pkl')\n",
    "    enc = joblib.load('label_encoder_final.pkl')\n",
    "    cols = joblib.load('feature_order.pkl')\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame([[N, P, K, temp, hum, ph, rain]], \n",
    "                        columns=['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "    \n",
    "    # Feature Engineering (Must match training!)\n",
    "    data['total_nutrients'] = data['N'] + data['P'] + data['K'] + 1e-5\n",
    "    data['N_ratio'] = data['N'] / data['total_nutrients']\n",
    "    data['P_ratio'] = data['P'] / data['total_nutrients']\n",
    "    data['K_ratio'] = data['K'] / data['total_nutrients']\n",
    "    data['aridity_index'] = data['rainfall'] / (data['temperature'] + 1e-5)\n",
    "    data['water_stress'] = data['temperature'] * (100 - data['humidity'])\n",
    "    \n",
    "    # Drop redundant & Enforce Order\n",
    "    data = data.drop(['total_nutrients'], axis=1)\n",
    "    data = data[cols]\n",
    "    \n",
    "    # Scale & Predict\n",
    "    scaled = sc.transform(data)\n",
    "    probs = model.predict_proba(scaled)\n",
    "    best_idx = np.argmax(probs)\n",
    "    label = enc.inverse_transform([best_idx])[0]\n",
    "    conf = probs[0][best_idx] * 100\n",
    "    \n",
    "    return label, conf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0145a5e3-a77f-4f3d-aaf3-2241ca5b9ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test Prediction (Rice Conditions):\n",
      "   Result: rice (53.23%)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "pred, conf = test_prediction(80, 40, 40, 25, 80, 7, 250)\n",
    "print(f\"\\nüß™ Test Prediction (Rice Conditions):\")\n",
    "print(f\"   Result: {pred} ({conf:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45f5e283-82fa-41d2-b40d-bcec064e6373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading fat model...\n",
      "üíæ Compressing and re-saving...\n",
      "‚úÖ Done! Check the file size now.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Load the fat model\n",
    "print(\"‚è≥ Loading fat model...\")\n",
    "model = joblib.load('crop_model_final.pkl')\n",
    "\n",
    "# Re-save with High Compression (Level 3 is a good balance)\n",
    "print(\"üíæ Compressing and re-saving...\")\n",
    "joblib.dump(model, 'crop_model_final.pkl', compress=3)\n",
    "\n",
    "print(\"‚úÖ Done! Check the file size now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1bf1a-de43-4913-86d3-3063d32c2aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
