{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fdbe4e1-4eff-4fd6-832d-8ab84296b67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Loaded. Shape: (5410, 11)\n",
      "   Columns: ['Temperature', 'Moisture', 'Rainfall', 'PH', 'Nitrogen', 'Phosphorous', 'Potassium', 'Carbon', 'Soil', 'Crop', 'Fertilizer']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "import xgboost as xgb\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load Data\n",
    "# ==============================================================================\n",
    "file_path = 'fertlizer_recommendation_dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"‚úÖ Data Loaded. Shape: {df.shape}\")\n",
    "    print(f\"   Columns: {df.columns.tolist()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå CRITICAL ERROR: '{file_path}' not found.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6b5100-8117-4a39-a2c7-968c90a3ba2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Encoding Labels...\n",
      "   ‚úÖ Encoded Soil: 5 classes\n",
      "   ‚úÖ Encoded Crop: 26 classes\n",
      "   ‚úÖ Encoded Target: 10 unique fertilizers\n",
      "üîí Feature Order Locked: ['Temperature', 'Moisture', 'Rainfall', 'PH', 'Soil', 'Crop', 'Nitrogen', 'Potassium', 'Phosphorous', 'Carbon']\n",
      "‚úÖ Data Split. Training on 4328 samples.\n",
      "‚öñÔ∏è Scaling Data...\n",
      "‚úÖ Data Scaled.\n"
     ]
    }
   ],
   "source": [
    "# 2. Encoding (Text -> Numbers)\n",
    "# ==============================================================================\n",
    "encoders = {}\n",
    "print(\"‚öôÔ∏è Encoding Labels...\")\n",
    "\n",
    "# Encode Features (Using correct column names 'Soil' and 'Crop')\n",
    "for col in ['Soil', 'Crop']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "    print(f\"   ‚úÖ Encoded {col}: {len(le.classes_)} classes\")\n",
    "\n",
    "# Encode Target (Fertilizer)\n",
    "le_target = LabelEncoder()\n",
    "df['Fertilizer'] = le_target.fit_transform(df['Fertilizer'])\n",
    "encoders['Target'] = le_target\n",
    "print(f\"   ‚úÖ Encoded Target: {len(le_target.classes_)} unique fertilizers\")\n",
    "\n",
    "# 3. Feature Setup & Ordering\n",
    "# ==============================================================================\n",
    "# Defining X with the exact column headers from your file\n",
    "# Note: Your file has 'Moisture' and 'Rainfall', but NO 'Humidity'.\n",
    "X = df[['Temperature', 'Moisture', 'Rainfall', 'PH', 'Soil', 'Crop', 'Nitrogen', 'Potassium', 'Phosphorous', 'Carbon']]\n",
    "y = df['Fertilizer']\n",
    "\n",
    "# SAVE FEATURE ORDER (Crucial for API stability)\n",
    "feature_order = X.columns.tolist()\n",
    "print(f\"üîí Feature Order Locked: {feature_order}\")\n",
    "\n",
    "# 4. Train/Test Split\n",
    "# ==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"‚úÖ Data Split. Training on {len(X_train)} samples.\")\n",
    "\n",
    "# 5. Scaling (StandardScaler)\n",
    "# ==============================================================================\n",
    "print(\"‚öñÔ∏è Scaling Data...\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data ONLY\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# Transform test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Data Scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0605aaf2-832c-4c6b-8732-8faf459ebdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuring Model Architectures for 3-Model Ensemble...\n",
      "‚úÖ Tuning Configuration Ready.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 6. Hyperparameter Tuning Setup (RF + XGB + KNN)\n",
    "# ==============================================================================\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "import xgboost as xgb # Ensure you have 'pip install xgboost' run separately!\n",
    "\n",
    "print(\"‚öôÔ∏è Configuring Model Architectures for 3-Model Ensemble...\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. Hyperparameter Tuning Setup (RF + KNN + XGB)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# 1. Random Forest (RF)\n",
    "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_params = {\n",
    "    'n_estimators': randint(150, 300),\n",
    "    'max_depth': [15, 20, 25, None],\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 4)\n",
    "}\n",
    "\n",
    "# 2. K-Nearest Neighbors (KNN)\n",
    "knn_base = KNeighborsClassifier(n_jobs=-1)\n",
    "knn_params = {\n",
    "    'n_neighbors': randint(3, 15),\n",
    "    'weights': ['distance'], \n",
    "    'p': [1, 2]              \n",
    "}\n",
    "\n",
    "# 3. XGBoost (XGB)\n",
    "xgb_base = xgb.XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "xgb_params = {\n",
    "    'n_estimators': randint(150, 300),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'subsample': uniform(0.7, 0.3)\n",
    "}\n",
    "\n",
    "# Dictionary to hold the search objects\n",
    "model_searches = {\n",
    "    'rf': RandomizedSearchCV(rf_base, rf_params, n_iter=15, cv=3, scoring='accuracy', n_jobs=-1, random_state=42),\n",
    "    'knn': RandomizedSearchCV(knn_base, knn_params, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42),\n",
    "    'xgb': RandomizedSearchCV(xgb_base, xgb_params, n_iter=15, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Tuning Configuration Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2f8a5-90e8-4c28-8b81-bd1a3a081b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting 3-Model Training Pipeline...\n",
      "\n",
      "üîé Tuning RF...\n",
      "   Best Score: 0.9353\n",
      "\n",
      "üîé Tuning KNN...\n",
      "   Best Score: 0.8341\n",
      "\n",
      "üîé Tuning XGB...\n",
      "   Best Score: 0.9360\n",
      "\n",
      "üèóÔ∏è Assembling Final Voting Ensemble...\n",
      "\n",
      "‚úÖ Final 3-Model Ensemble Trained.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 7. Train Optimized Ensemble\n",
    "# ==============================================================================\n",
    "def train_and_assemble(model_searches, X_train_scaled, y_train):\n",
    "    print(\"üöÄ Starting 3-Model Training Pipeline...\")\n",
    "    \n",
    "    best_estimators = []\n",
    "    \n",
    "    # Phase 1: Tuning\n",
    "    for name, search in model_searches.items():\n",
    "        print(f\"\\nüîé Tuning {name.upper()}...\")\n",
    "        search.fit(X_train_scaled, y_train)\n",
    "        print(f\"   Best Score: {search.best_score_:.4f}\")\n",
    "        best_estimators.append((name, search.best_estimator_))\n",
    "        \n",
    "    # Phase 2: Ensemble Training\n",
    "    print(\"\\nüèóÔ∏è Assembling Final Voting Ensemble...\")\n",
    "    \n",
    "    # Soft Voting: Averages the probabilities from RF, KNN, and XGB\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=best_estimators,\n",
    "        voting='soft', \n",
    "        n_jobs=1  # CRITICAL: Set to 1 to prevent Windows crash\n",
    "    )\n",
    "    \n",
    "    # Fit the Ensemble ONCE\n",
    "    ensemble.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "# Execute\n",
    "final_model = train_and_assemble(model_searches, X_train_scaled, y_train)\n",
    "print(\"\\n‚úÖ Final 3-Model Ensemble Trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8ed272-6c84-4356-891e-6a28e5c6c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Final Evaluation...\n",
      "\n",
      "üèÜ Final Test Accuracy: 95.75%\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   Balanced Npk Fertilizer       0.98      0.98      0.98        57\n",
      "                   Compost       0.99      0.98      0.99       108\n",
      "                       Dap       0.97      0.99      0.98       376\n",
      "General Purpose Fertilizer       0.75      0.82      0.78        11\n",
      "                    Gypsum       0.95      0.90      0.93        21\n",
      "                      Lime       0.81      0.87      0.84        54\n",
      "         Muriate Of Potash       0.97      0.96      0.97       106\n",
      "        Organic Fertilizer       0.88      0.92      0.90        38\n",
      "                      Urea       0.92      0.89      0.90        62\n",
      "Water Retaining Fertilizer       0.98      0.95      0.96       249\n",
      "\n",
      "                  accuracy                           0.96      1082\n",
      "                 macro avg       0.92      0.93      0.92      1082\n",
      "              weighted avg       0.96      0.96      0.96      1082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluation\n",
    "# ==============================================================================\n",
    "print(\"üìä Final Evaluation...\")\n",
    "preds = final_model.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(f\"\\nüèÜ Final Test Accuracy: {acc*100:.2f}%\")\n",
    "target_names = encoders['Target'].classes_.astype(str)\n",
    "print(classification_report(y_test, preds, target_names=target_names))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58dbccf2-65ed-4c6b-a616-c2d8df1d0792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Success! All artifacts saved to 'fertilizer_model_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "# 9. Save Artifacts (The Deployment Package)\n",
    "# ==============================================================================\n",
    "artifacts = {\n",
    "    'model': final_model,\n",
    "    'encoders': encoders,\n",
    "    'scaler': scaler,          \n",
    "    'feature_order': feature_order \n",
    "}\n",
    "\n",
    "joblib.dump(artifacts, 'fertilizer_model_final.pkl', compress=3)\n",
    "print(\"\\nüíæ Success! All artifacts saved to 'fertilizer_model_final.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55fccf-5e4d-4bfd-8f80-305a3d37c41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
